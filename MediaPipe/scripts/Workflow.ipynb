{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e73e623-3d6e-4041-9f31-b569a82db1d0",
   "metadata": {},
   "source": [
    "### Imports and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa76a953-84e6-493e-b669-469f0e0bdcad",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7601565-74b8-4cb3-8eeb-76048b9cafd5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def unit_vector(vector):\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "def distance(v1, v2):\n",
    "    if len(v1) != len(v2):\n",
    "        raise ValueError(\"Vectors must be of same dimensions!\")\n",
    "    \n",
    "    squared_sum = sum((a - b) ** 2 for a, b in zip(v1, v2))\n",
    "    return math.sqrt(squared_sum)\n",
    "\n",
    "def create_pose(mp_pose):\n",
    "    return mp_pose.Pose(\n",
    "        static_image_mode=False,\n",
    "        model_complexity=1,\n",
    "        enable_segmentation=False,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5,\n",
    "        smooth_landmarks=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71cf0fb-a396-4b17-9c6a-5c9f1c0d93bb",
   "metadata": {},
   "source": [
    "---\n",
    "### Play video\n",
    "#### without marker names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc3b4e3-9f43-45f4-9548-6d89038ff224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_without_markers(video_path, rotate_video_by_degrees, mp_pose):\n",
    "    \"\"\"Displays the video with markers from MediaPipe, but without their names.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    pose = create_pose(mp_pose)\n",
    "    \n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "            \n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        if (rotate_video_by_degrees != 0):\n",
    "            if (rotate_video_by_degrees == 90):\n",
    "                frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "            elif(rotate_video_by_degrees == 180):\n",
    "                frame = cv2.rotate(frame, cv2.ROTATE_180)\n",
    "            elif(rotate_video_by_degrees == 270):\n",
    "                frame = cv2.rotate(frame, cv2.ROTATE_270)     \n",
    "            \n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame,\n",
    "                results.pose_landmarks,\n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2)\n",
    "            )\n",
    "        cv2.imshow(\"Video (without names)\", frame)\n",
    "\n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32c66fe-7562-429f-9af7-12685b3bce61",
   "metadata": {},
   "source": [
    "#### with marker names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775b7881-287d-4e4a-9d53-91d042a9d7b4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def play_with_markers(video_path, rotate_video_by_degrees, mp_pose):\n",
    "    \"\"\"Displays the video with markers and their names.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    pose = create_pose(mp_pose)\n",
    "\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        \n",
    "        \n",
    "        if (rotate_video_by_degrees != 0):\n",
    "            if (rotate_video_by_degrees == 90):\n",
    "                frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "            elif(rotate_video_by_degrees == 180):\n",
    "                frame = cv2.rotate(frame, cv2.ROTATE_180)\n",
    "            elif(rotate_video_by_degrees == 270):\n",
    "                frame = cv2.rotate(frame, cv2.ROTATE_270)\n",
    "\n",
    "        # BGR -> RGB\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            # draw pose\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame,\n",
    "                results.pose_landmarks,\n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2)\n",
    "            )\n",
    "\n",
    "            # display marker names\n",
    "            h, w, _ = frame.shape\n",
    "            for idx, landmark in enumerate(results.pose_landmarks.landmark):\n",
    "                cx, cy = int(landmark.x * w), int(landmark.y * h)\n",
    "                name = mp_pose.PoseLandmark(idx).name\n",
    "                cv2.putText(frame, name, (cx + 5, cy - 5),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow(\"Video (with names)\", frame)\n",
    "\n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165a3437-155b-44ac-bb02-29ac8632b309",
   "metadata": {},
   "source": [
    "---\n",
    "### CSV Export of MediaPipe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9169354e-cb11-4632-8507-a83173ed29ae",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def pose_estimation(video, marker_names, landmark_map, video_folder, output_folder, rotate_video_by_degrees, flip_x_axis, mp_pose):\n",
    "    \"\"\"Runs the MediaPipe pose estimation on the video and extracts marker positions into a csv file.\"\"\"\n",
    "    print(\"Running pose estimation...\")\n",
    "    csv_path = output_folder + video + \".csv\"\n",
    "    video_path = video_folder + video + \".mp4\"\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    pose = create_pose(mp_pose)\n",
    "    \n",
    "    # CSV-File\n",
    "    with open(csv_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "    \n",
    "        # Meta/FPS\n",
    "        writer.writerow([\"#FPS\", cap.get(cv2.CAP_PROP_FPS)])\n",
    "    \n",
    "        # Header: Frame + Marker X/Y/Z\n",
    "        header = [\"Frame\"]\n",
    "        for m in marker_names:\n",
    "            header += [f\"{m}_X\", f\"{m}_Y\", f\"{m}_Z\"]\n",
    "        writer.writerow(header)\n",
    "    \n",
    "        frame_idx = 0\n",
    "    \n",
    "        while cap.isOpened():\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "                \n",
    "            if (rotate_video_by_degrees != 0):\n",
    "                if (rotate_video_by_degrees == 90):\n",
    "                    frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "                elif(rotate_video_by_degrees == 180):\n",
    "                    frame = cv2.rotate(frame, cv2.ROTATE_180)\n",
    "                elif(rotate_video_by_degrees == 270):\n",
    "                    frame = cv2.rotate(frame, cv2.ROTATE_270)\n",
    "                    \n",
    "            # BGR -> RGB\n",
    "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = pose.process(image_rgb)\n",
    "    \n",
    "            row = [frame_idx]\n",
    "    \n",
    "            if results.pose_landmarks:\n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "    \n",
    "                for m in marker_names:\n",
    "    \n",
    "                    idx = landmark_map[m]\n",
    "                    lm = landmarks[idx]\n",
    "                    \n",
    "                    if (flip_x_axis):\n",
    "                        lm.x = -lm.x\n",
    "                    # invert y axis\n",
    "                    row += [lm.x, -lm.y, lm.z]\n",
    "    \n",
    "            else:\n",
    "                # if no landmark - fill with 0s\n",
    "                row += [0.0] * (len(marker_names) * 3)\n",
    "    \n",
    "            writer.writerow(row)\n",
    "            frame_idx += 1\n",
    "    cap.release()\n",
    "    pose.close()\n",
    "    print(\"Pose estimation complete and output file successfully created: \" + csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d82b53-3597-49a1-b7fc-10665d3eb903",
   "metadata": {},
   "source": [
    "---\n",
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7f63f4-51f5-43e3-9143-0491025181dd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def scale(static_name, video_name, markers, limb_groups, anchor_marker, anchor_vector, csv_folder, reference_limb=None, reference_length=None, plots=False):\n",
    "    \"\"\"Scales data over given csv files.\n",
    "    <ul>\n",
    "        <li>Calculates origin displacement by averaging anchor position in static pose.</li>\n",
    "        <li>Calculates average lengths of limbs in static pose.</li>\n",
    "        <li>Corrects origin displacement and fixes lengths in static pose and movement video by\n",
    "            <ul>\n",
    "                <li>applying the origin displacement vector</li>\n",
    "                <li>iterating over the limbs array, <b>fixing the length by moving the second marker according to the first</b></li>\n",
    "            </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "    \"\"\"\n",
    "\n",
    "    def scale_to_distance(v0, v1, new_distance):\n",
    "        d = v1 - v0\n",
    "        dist = distance(v0, v1)\n",
    "\n",
    "        if dist == 0:\n",
    "            return v0\n",
    "\n",
    "        f = new_distance / dist\n",
    "        d_scaled = f * d\n",
    "\n",
    "        return v0 + d_scaled\n",
    "    \n",
    "\n",
    "    def shift_vector_to_distance(v0, v1, new_distance):\n",
    "        direction = v1 - v0\n",
    "        dist = distance(v0, v1)\n",
    "\n",
    "        if dist == 0:\n",
    "            return np.array([0, 0, 0])\n",
    "        \n",
    "        f = new_distance / dist\n",
    "        \n",
    "        v_new = v0 + f * direction\n",
    "\n",
    "        return v_new - v1\n",
    "    \n",
    "\n",
    "    def calc_scaled_lengths(reference_limb, reference_length, lengths):\n",
    "        \"\"\"Calculates average length of given limb over static pose. Takes factor between that value and given length and applies it to each others limbs average length.\"\"\"\n",
    "        avg_lengths = {}\n",
    "\n",
    "        factor = reference_length / lengths.mean(numeric_only=True).loc[reference_limb]\n",
    "\n",
    "        for group in limb_groups:\n",
    "            for limb in group:\n",
    "                avg_lengths[limb] = lengths.mean(numeric_only=True).loc[limb] * factor\n",
    "        \n",
    "        return avg_lengths\n",
    "\n",
    "\n",
    "    def get_data(file_path):\n",
    "        \"\"\"Load data from given csv and return as tuple: (first_line, dataframe).\"\"\"\n",
    "        file_path = file_path + \".csv\"\n",
    "        with open(file_path, \"r\") as f:\n",
    "            first_line = f.readline().strip()\n",
    "            df = pd.read_csv(file_path, comment=\"#\")\n",
    "        return first_line, df\n",
    "    \n",
    "    def get_origin_displacement(df, anchor_marker, anchor_vector):\n",
    "        \"\"\"Calculates vector between position of model marker and average position of the same marker in mediapipe data. Returns the vector as a numpy array\"\"\"\n",
    "        avg_anchor = df.mean(numeric_only=True).loc[anchor_marker + \"_X\": anchor_marker + \"_Z\"]\n",
    "        \n",
    "        return np.array(avg_anchor) - anchor_vector\n",
    "        \n",
    "    def calc_lengths(df):\n",
    "        lengths = pd.DataFrame(columns=[limb for group in limb_groups for limb in group], dtype=float)\n",
    "        \n",
    "        # calculate lengths for each limb in each frame\n",
    "        for frame in range(len(df)):\n",
    "            frame_data = df.iloc[frame]\n",
    "            l_row = {limb: 0 for group in limb_groups for limb in group}\n",
    "            \n",
    "            for group in limb_groups:\n",
    "                for limb in group:\n",
    "                    first = np.array([frame_data[markers[limb[0]] + \"_X\"], frame_data[markers[limb[0]] + \"_Y\"], frame_data[markers[limb[0]] + \"_Z\"]])\n",
    "                    second = np.array([frame_data[markers[limb[1]] + \"_X\"], frame_data[markers[limb[1]] + \"_Y\"], frame_data[markers[limb[1]] + \"_Z\"]])\n",
    "                    \n",
    "                    l_row[limb] = distance(first, second)\n",
    "            lengths.loc[len(lengths)] = l_row\n",
    "        return lengths\n",
    "\n",
    "\n",
    "    def scale_file(file_name, first_line, df, lengths, origin_displacement, scale_to=None):\n",
    "        \"\"\"Actual scaling based on given input. Also plots lengths over time if plots=True, to check for mistakes after scaling.\n",
    "        <br>scale_to holds the lengths to scale the limbs to. If not given, lengths will be calculated by averaging the lengths from the given dataframe.\"\"\"\n",
    "        scaled_path = csv_folder + file_name + \"_scaled.csv\"\n",
    "    \n",
    "        limb_count = 0\n",
    "\n",
    "        # plot lengths before scaling\n",
    "        if plots:\n",
    "            limb_count = sum(len(group) for group in limb_groups)\n",
    "            p = lengths.plot(y=[i for i in range(limb_count)], label=[(markers[limb[0]], markers[limb[1]]) for group in limb_groups for limb in group], title=file_name + \" unscaled\", xlabel=\"Frame\", ylabel=\"Length in m\")\n",
    "            p.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "            p.plot()\n",
    "\n",
    "        # if no lengths to scale to are give, calculate average length per limb\n",
    "        if scale_to is None:\n",
    "            scale_to = lengths.mean(numeric_only=True)\n",
    "    \n",
    "        scaled_df = df.head(0).copy()\n",
    "        \n",
    "        for i in range(len(df)):\n",
    "            row = df.iloc[i].copy()\n",
    "\n",
    "            # correct origin displacement\n",
    "            for m in range(len(markers)):\n",
    "                marker = markers[m]\n",
    "                v = np.array([row[marker + \"_X\"], row[marker + \"_Y\"], row[marker + \"_Z\"]]) - origin_displacement\n",
    "                row[marker + \"_X\"] = v[0]\n",
    "                row[marker + \"_Y\"] = v[1]\n",
    "                row[marker + \"_Z\"] = v[2]\n",
    "\n",
    "            for group in limb_groups:\n",
    "                cum_scale_v = np.array([0, 0, 0], dtype=float)\n",
    "                for limb in group:\n",
    "                    m0 = markers[limb[0]]\n",
    "                    m1 = markers[limb[1]]\n",
    "                    \n",
    "                    v0 = np.array([row[m0 + \"_X\"], row[m0 + \"_Y\"], row[m0 + \"_Z\"]])\n",
    "                    v1 = np.array([row[m1 + \"_X\"], row[m1 + \"_Y\"], row[m1 + \"_Z\"]]) + cum_scale_v\n",
    "            \n",
    "                    # new_v = scale_to_distance(v0, v1, scale_to[limb])\n",
    "                    curr_scale_v = shift_vector_to_distance(v0, v1, scale_to[limb])\n",
    "                    cum_scale_v += curr_scale_v\n",
    "                    \n",
    "                    # row[m1 + \"_X\"] = new_v[0]\n",
    "                    # row[m1 + \"_Y\"] = new_v[1]\n",
    "                    # row[m1 + \"_Z\"] = new_v[2]\n",
    "                    \n",
    "                    row[m1 + \"_X\"] = v1[0] + curr_scale_v[0]\n",
    "                    row[m1 + \"_Y\"] = v1[1] + curr_scale_v[1]\n",
    "                    row[m1 + \"_Z\"] = v1[2] + curr_scale_v[2]\n",
    "\n",
    "            scaled_df.loc[len(scaled_df)] = row\n",
    "    \n",
    "        # plot lengths after scaling\n",
    "        if plots:\n",
    "            scaled_lengths = calc_lengths(scaled_df)\n",
    "\n",
    "            p = scaled_lengths.plot(y=[i for i in range(limb_count)], label=[(markers[limb[0]], markers[limb[1]]) for group in limb_groups for limb in group], title=file_name + \" scaled\", xlabel=\"Frame\", ylabel=\"Length in m\")\n",
    "            p.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "            p.plot()\n",
    "        \n",
    "        with open(scaled_path, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "        \n",
    "            # Meta/FPS\n",
    "            file.write(first_line + \"\\n\")\n",
    "        \n",
    "            # Header: Frame + Marker X/Y/Z\n",
    "            header = []\n",
    "            for m in scaled_df.head():\n",
    "                header += [m]\n",
    "            writer.writerow(header)\n",
    "            \n",
    "            for r in range(len(scaled_df)):\n",
    "                row = []\n",
    "                cr = scaled_df.iloc[r]\n",
    "                for val in range(len(cr)):\n",
    "                    row.append(cr.iloc[val])\n",
    "                writer.writerow(row)\n",
    "                \n",
    "        print(\"Scaling complete and output file successfully created: \" + scaled_path)\n",
    "        return scale_to\n",
    "\n",
    "    # get data and origin displacement of static pose\n",
    "    first_line, df = get_data(csv_folder + static_name)\n",
    "    origin_d = get_origin_displacement(df, anchor_marker, anchor_vector)\n",
    "\n",
    "    # calculate lengths for each frame of static pose\n",
    "    lengths = calc_lengths(df)\n",
    "\n",
    "    print(\"Scaling static...\")\n",
    "    if (not reference_limb or not reference_length):\n",
    "        # no fixed length given -> calculate average lengths from static pose for scaling\n",
    "        scale_to = scale_file(static_name, first_line, df, lengths, origin_d)\n",
    "    else:\n",
    "        # fixed length for limb given -> calculate average lengths from static pose, calculate factor for chosen limb and apply to other average lengths to get scaling lengths\n",
    "        scale_to = calc_scaled_lengths(reference_limb, reference_length, lengths)\n",
    "        scale_file(static_name, first_line, df, lengths, origin_d, scale_to)\n",
    "\n",
    "    # get data of movement video\n",
    "    first_line, df = get_data(csv_folder + video_name)\n",
    "    \n",
    "    # calculate lengths for each frame of movement video\n",
    "    lengths = calc_lengths(df)\n",
    "\n",
    "    print(\"Scaling video...\")\n",
    "    scale_file(video_name, first_line, df, lengths, origin_d, scale_to)\n",
    "    \n",
    "    return static_name + \"_scaled\", video_name + \"_scaled\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6975df-af36-4abe-a458-cf8d909fb924",
   "metadata": {},
   "source": [
    "---\n",
    "### .csv to .trc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f165d61b-0448-4e29-b27f-905678703070",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def to_trc(video_name, output_folder):\n",
    "    \"\"\"\n",
    "    Reads .csv and writes coordinates to formatted .trc file for import to OpenSim.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Converting to .trc file...\")\n",
    "    trc_path = output_folder + video_name + \".trc\"\n",
    "    units = \"m\"\n",
    "    \n",
    "    csv_path = output_folder + video_name + \".csv\"\n",
    "    \n",
    "    with open(csv_path, \"r\") as f:\n",
    "        first_line = f.readline().strip()\n",
    "    \n",
    "    fps = 30\n",
    "    if first_line.startswith(\"#FPS\"):\n",
    "        fps = float(first_line.split(\",\")[1].strip())\n",
    "    \n",
    "    data_rate = fps\n",
    "    camera_rate = fps\n",
    "    \n",
    "    # load csv\n",
    "    df = pd.read_csv(csv_path, comment=\"#\")\n",
    "    \n",
    "    # calculate time based on fps\n",
    "    if \"frame\" in df.columns:\n",
    "        df[\"Time\"] = df[\"frame\"] / data_rate\n",
    "        df = df.drop(columns=[\"frame\"])\n",
    "    else:\n",
    "        df[\"Time\"] = [i / data_rate for i in range(len(df))]\n",
    "    \n",
    "    # extract marker names\n",
    "    markers = sorted(set(col.rsplit(\"_\", 1)[0] for col in df.columns if col.endswith(\"_X\")))\n",
    "    \n",
    "    # prepare trc header\n",
    "    n_markers = len(markers)\n",
    "    n_frames = len(df)\n",
    "    header = [\n",
    "        \"PathFileType\\t4\\t(X/Y/Z)\\t\" + trc_path,\n",
    "        \"DataRate\\tCameraRate\\tNumFrames\\tNumMarkers\\tUnits\\tOrigDataRate\\tOrigDataStartFrame\\tOrigNumFrames\",\n",
    "        f\"{data_rate}\\t{camera_rate}\\t{n_frames}\\t{n_markers}\\t{units}\\t{data_rate}\\t1\\t{n_frames}\",\n",
    "    ]\n",
    "    \n",
    "    # columns for trc (OpenSim expects: Frame#, Time, Marker1 X Y Z, Marker2 X Y Z, ...)\n",
    "    trc_header = [\"Frame#\", \"Time\"]\n",
    "    for m in markers:\n",
    "        trc_header.extend([f\"{m}\\t\\t\"])\n",
    "    header.append(\"\\t\".join(trc_header))\n",
    "    \n",
    "    coordinatesHeader = \"\".join(\n",
    "        [f\"X{i}\\tY{i}\\tZ{i}\\t\" for i in range(1, len(markers) + 1)]\n",
    "    )\n",
    "    \n",
    "    header.append(\"\\t\\t\" + coordinatesHeader + \"\\n\\n\")\n",
    "    \n",
    "    # prepare rows\n",
    "    rows = []\n",
    "    for i, row in df.iterrows():\n",
    "        frame_num = i + 1\n",
    "        line = [f\"{frame_num}\", f\"{row['Time']:.5f}\"]\n",
    "        for m in markers:\n",
    "            x, y, z = row.get(f\"{m}_X\", float(\"nan\")), row.get(f\"{m}_Y\", float(\"nan\")), row.get(f\"{m}_Z\", float(\"nan\"))\n",
    "            line.extend([f\"{x:.5f}\" + f\"\\t{y:.5f}\" + f\"\\t{z:.5f}\"])\n",
    "        rows.append(\"\\t\".join(line))\n",
    "    \n",
    "    # write trc file\n",
    "    with open(trc_path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(header))\n",
    "        f.write(\"\\n\".join(rows))\n",
    "    \n",
    "    print(f\"trc file successfully created: {trc_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994bdc4a-d456-4700-b283-8436cf3e6b78",
   "metadata": {},
   "source": [
    "---\n",
    "### Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c1d774-f335-477d-8d94-24ab641700bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust these variables accordingly\n",
    "static_name = \"T-Pose_pullover\"\n",
    "video_name = \"Bein\"\n",
    "\n",
    "video_folder = \"../../Videos/\"\n",
    "output_folder = \"../output/\"\n",
    "\n",
    "static_path = video_folder + static_name + \".mp4\"\n",
    "video_path = video_folder + video_name + \".mp4\"\n",
    "\n",
    "# turns video clockwise, options are 0, 90, 180 and 270\n",
    "rotate_video_by_degrees = 0\n",
    "\n",
    "\n",
    "# create MediaPipe pose instance\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# list of markers, these names have to be adjusted to the names of the OpenSim model markers\n",
    "# marker_names = [\"r_acromion\", \"r_humerus_epicondyle\", \"r_radius_styloid\"]\n",
    "\n",
    "marker_names = [\n",
    "        \"NOSE\",\n",
    "        \"LEFT_EYE_INNER\",\n",
    "        \"LEFT_EYE\",\n",
    "        \"LEFT_EYE_OUTER\",\n",
    "        \"RIGHT_EYE_INNER\",\n",
    "        \"RIGHT_EYE\",\n",
    "        \"RIGHT_EYE_OUTER\",\n",
    "        \"LEFT_EAR\",\n",
    "        \"RIGHT_EAR\",\n",
    "        \"MOUTH_LEFT\",\n",
    "        \"MOUTH_RIGHT\",\n",
    "        \"LEFT_SHOULDER\",\n",
    "        \"RIGHT_SHOULDER\",\n",
    "        \"LEFT_ELBOW\",\n",
    "        \"RIGHT_ELBOW\",\n",
    "        \"LEFT_WRIST\",\n",
    "        \"RIGHT_WRIST\",\n",
    "        \"LEFT_PINKY\",\n",
    "        \"RIGHT_PINKY\",\n",
    "        \"LEFT_INDEX\",\n",
    "        \"RIGHT_INDEX\",\n",
    "        \"LEFT_THUMB\",\n",
    "        \"RIGHT_THUMB\",\n",
    "        \"LEFT_HIP\",\n",
    "        \"RIGHT_HIP\",\n",
    "        \"LEFT_KNEE\",\n",
    "        \"RIGHT_KNEE\",\n",
    "        \"LEFT_ANKLE\",\n",
    "        \"RIGHT_ANKLE\",\n",
    "        \"LEFT_HEEL\",\n",
    "        \"RIGHT_HEEL\",\n",
    "        \"LEFT_FOOT_INDEX\",\n",
    "        \"RIGHT_FOOT_INDEX\"\n",
    "]\n",
    "\n",
    "# Mapping Landmark-Index\n",
    "landmark_map = {\n",
    "    # all 33 mediapipe markers:\n",
    "    \"NOSE\": mp_pose.PoseLandmark.NOSE,\n",
    "    \"LEFT_EYE_INNER\": mp_pose.PoseLandmark.LEFT_EYE_INNER,\n",
    "    \"LEFT_EYE\": mp_pose.PoseLandmark.LEFT_EYE,\n",
    "    \"LEFT_EYE_OUTER\": mp_pose.PoseLandmark.LEFT_EYE_OUTER,\n",
    "    \"RIGHT_EYE_INNER\": mp_pose.PoseLandmark.RIGHT_EYE_INNER,\n",
    "    \"RIGHT_EYE\": mp_pose.PoseLandmark.RIGHT_EYE,\n",
    "    \"RIGHT_EYE_OUTER\": mp_pose.PoseLandmark.RIGHT_EYE_OUTER,\n",
    "    \"LEFT_EAR\": mp_pose.PoseLandmark.LEFT_EAR,\n",
    "    \"RIGHT_EAR\": mp_pose.PoseLandmark.RIGHT_EAR,\n",
    "    \"MOUTH_LEFT\": mp_pose.PoseLandmark.MOUTH_LEFT,\n",
    "    \"MOUTH_RIGHT\": mp_pose.PoseLandmark.MOUTH_RIGHT,\n",
    "    \"LEFT_SHOULDER\": mp_pose.PoseLandmark.LEFT_SHOULDER,\n",
    "    \"RIGHT_SHOULDER\": mp_pose.PoseLandmark.RIGHT_SHOULDER,\n",
    "    \"LEFT_ELBOW\": mp_pose.PoseLandmark.LEFT_ELBOW,\n",
    "    \"RIGHT_ELBOW\": mp_pose.PoseLandmark.RIGHT_ELBOW,\n",
    "    \"LEFT_WRIST\": mp_pose.PoseLandmark.LEFT_WRIST,\n",
    "    \"RIGHT_WRIST\": mp_pose.PoseLandmark.RIGHT_WRIST,\n",
    "    \"LEFT_PINKY\": mp_pose.PoseLandmark.LEFT_PINKY,\n",
    "    \"RIGHT_PINKY\": mp_pose.PoseLandmark.RIGHT_PINKY,\n",
    "    \"LEFT_INDEX\": mp_pose.PoseLandmark.LEFT_INDEX,\n",
    "    \"RIGHT_INDEX\": mp_pose.PoseLandmark.RIGHT_INDEX,\n",
    "    \"LEFT_THUMB\": mp_pose.PoseLandmark.LEFT_THUMB,\n",
    "    \"RIGHT_THUMB\": mp_pose.PoseLandmark.RIGHT_THUMB,\n",
    "    \"LEFT_HIP\": mp_pose.PoseLandmark.LEFT_HIP,\n",
    "    \"RIGHT_HIP\": mp_pose.PoseLandmark.RIGHT_HIP,\n",
    "    \"LEFT_KNEE\": mp_pose.PoseLandmark.LEFT_KNEE,\n",
    "    \"RIGHT_KNEE\": mp_pose.PoseLandmark.RIGHT_KNEE,\n",
    "    \"LEFT_ANKLE\": mp_pose.PoseLandmark.LEFT_ANKLE,\n",
    "    \"RIGHT_ANKLE\": mp_pose.PoseLandmark.RIGHT_ANKLE,\n",
    "    \"LEFT_HEEL\": mp_pose.PoseLandmark.LEFT_HEEL,\n",
    "    \"RIGHT_HEEL\": mp_pose.PoseLandmark.RIGHT_HEEL,\n",
    "    \"LEFT_FOOT_INDEX\": mp_pose.PoseLandmark.LEFT_FOOT_INDEX,\n",
    "    \"RIGHT_FOOT_INDEX\": mp_pose.PoseLandmark.RIGHT_FOOT_INDEX,\n",
    "    \n",
    "    # for arm model:\n",
    "    # \"r_acromion\" : mp_pose.PoseLandmark.RIGHT_SHOULDER,\n",
    "    # \"r_humerus_epicondyle\" : mp_pose.PoseLandmark.RIGHT_ELBOW,\n",
    "    # \"r_radius_styloid\" : mp_pose.PoseLandmark.RIGHT_WRIST\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8350e659-5d9a-4206-9a8d-4b2818fa90ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the first run, play the video to ensure its not rotated and correct the rotate_video_by_degrees variable if it is\n",
    "# play_without_markers(static_path, rotate_video_by_degrees, mp_pose)\n",
    "play_without_markers(video_path, rotate_video_by_degrees, mp_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b63e855-f688-451b-ba15-9a03ad4f1af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_with_markers(static_path, rotate_video_by_degrees, mp_pose)\n",
    "play_with_markers(video_path, rotate_video_by_degrees, mp_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d12805-b947-4b59-ad26-cfa211eccd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "flip_x_axis = True\n",
    "\n",
    "pose_estimation(static_name, marker_names, landmark_map, video_folder, output_folder, rotate_video_by_degrees, flip_x_axis, mp_pose)\n",
    "pose_estimation(video_name, marker_names, landmark_map, video_folder, output_folder, rotate_video_by_degrees, flip_x_axis, mp_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b23041-5683-41b1-92e9-5ea921800dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to look at marker positions for limbs array\n",
    "for i in range(len(marker_names)):\n",
    "    print(i, marker_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b74388-553b-404c-ae31-158b0025fc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "limb_groups = [\n",
    "    [(10, 9)], # mouth\n",
    "    [(0, 4), (4, 5), (5, 6), (6, 8)], # nose-(right) eye-ear\n",
    "    [(0, 1), (1, 2), (2, 3), (3, 7)], # nose-(left) eye-ear\n",
    "    [(12, 14), (14, 16)], # right arm\n",
    "    [(11, 13), (13, 15)], # left arm\n",
    "    [(14, 16), (26, 28)], # right leg\n",
    "    [(23, 25), (25, 27)] # left leg\n",
    "]         \n",
    "\n",
    "anchor_marker = \"RIGHT_SHOULDER\"\n",
    "\n",
    "# anchor_marker = \"r_acromion\"\n",
    "anchor_vector = np.array([0,0.837,0.17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7cf7ea-179c-46a2-b00c-99329e8c3d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_limb_for_scaling = None\n",
    "reference_length_for_scaling = None\n",
    "\n",
    "reference_limb_for_scaling = (0, 1)\n",
    "reference_length_for_scaling = 0.25\n",
    "\n",
    "static_scaled, video_scaled = scale(static_name, video_name, marker_names, limb_groups, anchor_marker, anchor_vector, output_folder, reference_limb_for_scaling, reference_length_for_scaling, plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8929b5-a552-4f31-a81f-66c3eff8e1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_trc(static_name, output_folder)\n",
    "to_trc(video_name, output_folder)\n",
    "\n",
    "# to_trc(static_scaled, output_folder)\n",
    "# to_trc(video_scaled, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c82697f-8a0c-4a86-8f5c-618b323e93df",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
