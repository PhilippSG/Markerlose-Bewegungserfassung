\chapter{Hauptteil}
\section{Ablauf bei der Verwendung von MediaPipe}
Im folgenden wird unserer Workflow beschrieben, den wir verwendet haben um mit MediaPipe zum Ziel zu kommen. 
\subsection{Importierung der Bibliotheken}
Es werden folgende Versionen der Module für die Verwendung mit Python verwendet:
\begin{itemize}
    \item csv (kommt mit python) 3.12.12 \newline
    Standard-Modul zum Schreiben von Textdateien im "Comma Separated Values" - Format.
    \item math (kommt mit python) 3.12.12 \newline
    Standard-Mathematik-Bibliothek von Python.
    \item cv2 4.12.0.88 (opencv-python) \newline
    Bibliothek für Computer Vision. Ist Notwendig zum lesen der Video Dateien und weiteren Bearbeitung. 
    \item MediaPipe 0.10.21 \newline
    Machine-Learning-Bibliotheken von Google. Wichtig für die Pose Schätzung.
    \item pandas 2.3.3 \newline
    Modul für die Datenanalyse und Tabellenkalkulation. Wichtig für die Umwandlung von CSV in TRC Datei.
    \item numpy 1.26.4 \newline
    Standardbibliothek für mathematische Berechnungen mit Vektoren und Matrizen. Wichtig für die Skalierung.
\end{itemize}
\subsection{Anzeigen der Videos}
Wir haben eine Funktion erstellt mit der unsere Videos, mit den eingezeichneten Skeletten von MediaPipe, angezeigt werden.
\begin{lstlisting}[language=Python, caption= Funktion zum Abspielen der Videos]
def play_video(video_path, rotate_video_by_degrees, mp_pose, display_marker_names=False):
    """Displays the video with markers from MediaPipe, but without their names."""
    cap = cv2.VideoCapture(video_path)

    pose = create_pose(mp_pose)
    
    mp_drawing = mp.solutions.drawing_utils

    while cap.isOpened():
        success, frame = cap.read()
            
        if not success:
            break

        if (rotate_video_by_degrees != 0):
            if (rotate_video_by_degrees == 90):
                frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)
            elif(rotate_video_by_degrees == 180):
                frame = cv2.rotate(frame, cv2.ROTATE_180)
            elif(rotate_video_by_degrees == 270):
                frame = cv2.rotate(frame, cv2.ROTATE_270)     
            
        # BGR -> RGB
        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = pose.process(image_rgb)

        if results.pose_landmarks:
            mp_drawing.draw_landmarks(
                frame,
                results.pose_landmarks,
                mp_pose.POSE_CONNECTIONS,
                mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),
                mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2)
            )

        if (display_marker_names):
            h, w, _ = frame.shape
            for idx, landmark in enumerate(results.pose_landmarks.landmark):
                cx, cy = int(landmark.x * w), int(landmark.y * h)
                name = mp_pose.PoseLandmark(idx).name
                cv2.putText(frame, name, (cx + 5, cy - 5),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 255), 1, cv2.LINE_AA)

        cv2.imshow("Video", frame)

        if cv2.waitKey(5) & 0xFF == ord('q'):
            break
    
    cap.release()
    cv2.destroyAllWindows()
\end{lstlisting}
Die Funktion benötigt vier Übergabevariablen um das Video anzuzeigen:
\begin{enumerate}
    \item \verb|videopath|: Der Pfad zum Video
    \item \verb|rotate_video_by_degrees|: Die Gradzahl, um die das Video beim Anzeigen rotiert wird.
    \item \verb|mp_pose|: Die von MediaPipe erstellte Posen-Schätzung
    \item \verb|display_marker_names|: Flag Variable, um das Video mit benannten Markern zu erstellen. Standardmäßig aus.
\end{enumerate}
\subsection{Erstellen einer CSV mit MediaPipe Daten aus einem brauchbaren Video}
\subsection{Skalierung der MediaPipe Daten}
Da MediaPipe die erkannten 3D-Koordinaten in einem normierten Raum zurückgibt, müssen diese Koordinaten
skaliert werden, um sie in OpenSim verwenden zu können. Dabei geht es hauptsächlich darum, die Längen
von Körperteilen korrekt darzustellen und nicht über die frames variieren zu lassen und den Ursprung der
MediaPipe Daten auf den Ursprung von OpenSim zu verschieben.

Für die Ursprungsverschiebung muss ein Marker als Referenz gewählt und dessen Position in OpenSim als
Referenzkoordinate übergeben werden. Dann wird die durchschnittliche Koordinate dieses Markers über die
statische Aufnahme berechnet und der Differenzvektor zu der OpenSim Referenzkoordinate bestimmt. Dieser
Vektor wird dann auf alle MediaPipe Koordinaten addiert, um den Ursprung zu verschieben.

Die Skalierung der Körperteile kann auf verschiedene Arten erfolgen:
\begin{itemize}
    \item \textbf{Skalierung über die durchschnittliche Länge in der statischen Aufnahme:} Hier werden die Körperteile
    einfach auf die durchschnittlichen Längen in der statischen Aufnahme skaliert.
    \item \textbf{Skalierung über eine bekannte Referenzlänge:} Hierbei wird eine bekannte Länge 
    (z.B. die Länge eines Armes) verwendet. Dann wird ein Faktor zwischen dieser und der durchschnittlichen Länge des verwendeten
    Körperteils in der statischen Aufnahme berechnet und anschließend auf alle durchschnittlichen Längen aller Körperteile angewendet,
    um die skalierten Längen zu erhalten.

    Dies ist besonders nützlich, wenn die Person in der Aufnahme eine erhöhte Distanz zur Kamera hat.
\end{itemize}

Um die eigentliche Skalierung durchführen zu können, müssen zuerst die zu skalierenden Körperteile definiert werden.
Für eine saubere Skalierung und um Winkel zwischen den Körperteilen beizubehalten, können die Körperteile in Gruppen
zusammengefasst werden. Jede Gruppe kann aus mehreren verbundenen Körperteilen bestehen, die zusammen skaliert werden.
Im Code gibt es dafür das Array \texttt{limb\_groups}, welches die Indizes der
zu skalierenden Körperteile im \texttt{landmark\_map} dictionary als Tupel übergibt.
Bei einem einfachen Arme Modell, bestehend aus 6 Markern (jeweils Schulter, Ellbogen, Handgelenk), könnte dies wie folgt aussehen:
\begin{verbatim}
idx Marker_name
0   r_shoulder
1   r_elbow
2   r_wrist
3   l_shoulder
4   l_elbow
5   l_wrist


limb_groups = [
    [(0, 1), (1, 2)],
    [(3, 4), (4, 5)]
]
\end{verbatim}

Bei der Skalierung wird für jedes Tupel der zweite Marker an den ersten angepasst, daher ist die Reihenfolge hier entscheidend.
Nach der Verschiebung eines Markers wird ein Verschiebungsvektor aufaddiert, welcher vor der Skalierung des nächsten
Körperteils auch auf den zweiten Marker des Tupels angewendet wird, um die Winkel beizubehalten.
\subsection{Erstellen einer Tracer(.trc) Datei aus den Daten in der CSV Datei}
\subsection{Verwendung der Tracer Datei um die virtuellen Marker als experimentelle Marker in OpenSim anzeigen zu lassen}
\subsection{Anwendung auf ein Modell in OpenSim}
