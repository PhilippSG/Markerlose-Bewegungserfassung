\section{Stand der Technik/Modelle für markerlose Bewegungserfassung}
Der aktuelle Stand der Technik basiert überwiegend auf Verfahren der sogenannten Human Pose Estimation (HPE).
Dabei werden anatomisch definierte Gelenkpunkte, also sogenannte Keypoints, direkt aus Bild- oder Videodaten geschätzt.
Moderne Systeme nutzen hierfür überwiegend Deep-Learning-Modelle, insbesondere Convolutional Neural Networks (CNN),
die Gelenkpositionen in Form probabilistischer Heatmaps vorhersagen. Diese Verfahren erreichen in der zweidimensionalen
Pose-Schätzung inzwischen eine sehr hohe Genauigkeit und Robustheit gegenüber variierenden Hintergründen,
Beleuchtungsverhältnissen und Körperformen.

Die dreidimensionale markerlose Bewegungserfassung stellt weiterhin eine größere technische Herausforderung dar.
Ein grundlegendes Problem besteht in der sogenannten Tiefenambiguität, da aus monokularen RGB-Aufnahmen keine
eindeutige Tiefeninformation ableitbar ist. Aktuelle Forschungsansätze begegnen diesem Problem durch die Nutzung
mehrerer synchronisierter Kameras, durch lernbasierte Rekonstruktion dreidimensionaler Posen aus großen annotierten
Datensätzen oder durch zeitliche Modellierung ganzer Bewegungssequenzen. Insbesondere die Kombination räumlicher und
zeitlicher Informationen hat sich als wesentlich für robuste 3D-Rekonstruktionen erwiesen.

Neben rein monokularen Ansätzen kommen zunehmend Multi-View-Systeme zum Einsatz, bei denen mehrere Kameras aus
unterschiedlichen Blickwinkeln verwendet werden. Durch geometrische Triangulation lassen sich dabei dreidimensionale
Gelenkpositionen präziser bestimmen, insbesondere bei Bewegungen mit starker Selbstverdeckung. Diese Systeme erreichen
in kontrollierten Umgebungen eine Genauigkeit, die in bestimmten Anwendungen bereits mit markerbasierten
Motion-Capture-Systemen vergleichbar ist. Allerdings gehen sie mit höherem Hardware-, Kalibrierungs- und Rechenaufwand einher.

Ein weiterer Entwicklungszweig des Stands der Technik sind hybride Verfahren, die visuelle RGB-Daten mit Tiefeninformationen
aus Time-of-Flight- oder Stereo-Kameras kombinieren. Durch die explizite Messung der Entfernung zum Objekt kann die
dreidimensionale Rekonstruktion stabilisiert und die Fehleranfälligkeit bei Abdeckung der Sicht reduziert werden. Solche
Systeme finden insbesondere in der Rehabilitation, der ergonomischen Analyse und der Mensch-Maschine-Interaktion Anwendung.

In den letzten Jahren hat sich zudem der Einsatz fortgeschrittener neuronaler Architekturen wie Graph-Neural-Networks und
Transformer-Modelle etabliert. Diese ermöglichen eine explizite Modellierung der kinematischen Abhängigkeiten zwischen
einzelnen Gelenken sowie der zeitlichen Dynamik von Bewegungen. Aktuelle Forschungsarbeiten untersuchen darüber hinaus den
Einsatz generativer und diffusionsbasierter Modelle, um plausible 3D-Bewegungen auch bei unvollständigen oder verrauschten
Eingangsdaten zu rekonstruieren.

Trotz erheblicher Fortschritte bestehen weiterhin offene Herausforderungen. Dazu zählen die robuste Handhabung von Sichtabdeckung,
die Übertragbarkeit auf neue Personen und Umgebungen sowie die biomechanische Genauigkeit der rekonstruierten Bewegungen.
Insbesondere für Anwendungen, bei denen Gelenkmomente, Muskelkräfte oder Belastungen bestimmt werden sollen, ist die Kopplung
markerloser Bewegungserfassung mit biomechanischen Modellen weiterhin Gegenstand aktueller Forschung.

Zur Analyse und Simulation menschlicher Bewegungen existieren verschiedene etablierte Systeme digitaler Menschmodelle.
Zu den bekanntesten zählen AnyBody, OpenSim, Santos, LifeMOD und Dynamicus.